{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b3c63e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T21:33:14.504866Z",
     "iopub.status.busy": "2024-09-29T21:33:14.503836Z",
     "iopub.status.idle": "2024-09-29T21:33:16.508236Z",
     "shell.execute_reply": "2024-09-29T21:33:16.506484Z"
    },
    "papermill": {
     "duration": 2.016159,
     "end_time": "2024-09-29T21:33:16.511127",
     "exception": false,
     "start_time": "2024-09-29T21:33:14.494968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/playground-series-s4e9/sample_submission.csv\n",
      "/kaggle/input/playground-series-s4e9/train.csv\n",
      "/kaggle/input/playground-series-s4e9/test.csv\n",
      "/kaggle/input/lgbm-cat-bagging/__results__.html\n",
      "/kaggle/input/lgbm-cat-bagging/submission.csv\n",
      "/kaggle/input/lgbm-cat-bagging/__notebook__.ipynb\n",
      "/kaggle/input/lgbm-cat-bagging/__output__.json\n",
      "/kaggle/input/lgbm-cat-bagging/custom.css\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/version.txt\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/metadata.json\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/learner.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/predictor.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/utils/data/X.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/utils/data/y.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/trainer.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_r177_BAG_L1/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_r177_BAG_L1/S1F8/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_r177_BAG_L1/S1F2/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_r177_BAG_L1/utils/model_template.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_r177_BAG_L1/utils/oof.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_r177_BAG_L1/S1F3/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_r177_BAG_L1/S1F6/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_r177_BAG_L1/S1F4/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_r177_BAG_L1/S1F7/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_r177_BAG_L1/S1F1/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_r177_BAG_L1/S1F5/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMLarge_BAG_L1/S1F8/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMLarge_BAG_L1/S1F2/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMLarge_BAG_L1/S1F3/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMLarge_BAG_L1/S1F6/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMLarge_BAG_L1/S1F4/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMLarge_BAG_L1/S1F7/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMLarge_BAG_L1/S1F1/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMLarge_BAG_L1/S1F5/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_BAG_L1/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_BAG_L1/S1F8/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_BAG_L1/S1F2/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_BAG_L1/S1F3/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_BAG_L1/S1F6/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_BAG_L1/S1F4/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_BAG_L1/S1F7/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_BAG_L1/S1F1/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_BAG_L1/S1F5/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/WeightedEnsemble_L3/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/WeightedEnsemble_L3/utils/oof.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMXT_BAG_L2/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMXT_BAG_L2/S1F8/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMXT_BAG_L2/S1F2/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMXT_BAG_L2/S1F3/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMXT_BAG_L2/S1F6/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMXT_BAG_L2/S1F4/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMXT_BAG_L2/S1F7/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMXT_BAG_L2/S1F1/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMXT_BAG_L2/S1F5/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_BAG_L2/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_BAG_L2/S1F8/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_BAG_L2/S1F2/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_BAG_L2/S1F3/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_BAG_L2/S1F6/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_BAG_L2/S1F4/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_BAG_L2/S1F7/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_BAG_L2/S1F1/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_BAG_L2/S1F5/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_r131_BAG_L1/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_r131_BAG_L1/S1F8/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_r131_BAG_L1/S1F2/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_r131_BAG_L1/utils/model_template.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_r131_BAG_L1/utils/oof.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_r131_BAG_L1/S1F3/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_r131_BAG_L1/S1F6/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_r131_BAG_L1/S1F4/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_r131_BAG_L1/S1F7/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_r131_BAG_L1/S1F1/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBM_r131_BAG_L1/S1F5/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMXT_BAG_L1/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMXT_BAG_L1/S1F8/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMXT_BAG_L1/S1F2/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMXT_BAG_L1/S1F3/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMXT_BAG_L1/S1F6/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMXT_BAG_L1/S1F4/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMXT_BAG_L1/S1F7/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMXT_BAG_L1/S1F1/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMXT_BAG_L1/S1F5/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_BAG_L1/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_BAG_L1/S1F8/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_BAG_L1/S1F2/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_BAG_L1/S1F3/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_BAG_L1/S1F6/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_BAG_L1/S1F4/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_BAG_L1/S1F7/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_BAG_L1/S1F1/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_BAG_L1/S1F5/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/WeightedEnsemble_L2/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMLarge_BAG_L2/S1F8/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMLarge_BAG_L2/S1F2/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMLarge_BAG_L2/S1F3/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMLarge_BAG_L2/S1F6/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMLarge_BAG_L2/S1F4/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMLarge_BAG_L2/S1F7/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMLarge_BAG_L2/S1F1/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/LightGBMLarge_BAG_L2/S1F5/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_BAG_L2/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_BAG_L2/S1F8/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_BAG_L2/S1F2/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_BAG_L2/S1F3/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_BAG_L2/S1F6/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_BAG_L2/S1F4/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_BAG_L2/S1F7/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_BAG_L2/S1F1/model.pkl\n",
      "/kaggle/input/lgbm-cat-bagging/AutogluonModels/ag-20240929_172922/models/CatBoost_BAG_L2/S1F5/model.pkl\n",
      "/kaggle/input/goodluck2/sample_submission.csv\n",
      "/kaggle/input/goodluck2/submission_9.csv\n",
      "/kaggle/input/used-car-price-prediction-dataset/used_cars.csv\n",
      "/kaggle/input/used-cars/used_cars.csv\n",
      "/kaggle/input/catboost-xgboost-best-score/__results__.html\n",
      "/kaggle/input/catboost-xgboost-best-score/submission.csv\n",
      "/kaggle/input/catboost-xgboost-best-score/__notebook__.ipynb\n",
      "/kaggle/input/catboost-xgboost-best-score/__output__.json\n",
      "/kaggle/input/catboost-xgboost-best-score/custom.css\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/version.txt\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/metadata.json\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/learner.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/predictor.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/utils/data/X.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/utils/data/y.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/trainer.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_r177_BAG_L1/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_r177_BAG_L1/S1F8/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_r177_BAG_L1/S1F2/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_r177_BAG_L1/utils/model_template.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_r177_BAG_L1/utils/oof.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_r177_BAG_L1/S1F3/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_r177_BAG_L1/S1F6/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_r177_BAG_L1/S1F4/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_r177_BAG_L1/S1F7/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_r177_BAG_L1/S1F1/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_r177_BAG_L1/S1F5/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMLarge_BAG_L1/S1F8/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMLarge_BAG_L1/S1F2/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMLarge_BAG_L1/S1F3/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMLarge_BAG_L1/S1F6/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMLarge_BAG_L1/S1F4/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMLarge_BAG_L1/S1F7/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMLarge_BAG_L1/S1F1/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMLarge_BAG_L1/S1F5/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_BAG_L1/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_BAG_L1/S1F8/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_BAG_L1/S1F2/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_BAG_L1/S1F3/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_BAG_L1/S1F6/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_BAG_L1/S1F4/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_BAG_L1/S1F7/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_BAG_L1/S1F1/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_BAG_L1/S1F5/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/WeightedEnsemble_L3/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/WeightedEnsemble_L3/utils/oof.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMXT_BAG_L2/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMXT_BAG_L2/S1F8/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMXT_BAG_L2/S1F2/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMXT_BAG_L2/S1F3/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMXT_BAG_L2/S1F6/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMXT_BAG_L2/S1F4/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMXT_BAG_L2/S1F7/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMXT_BAG_L2/S1F1/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMXT_BAG_L2/S1F5/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_BAG_L2/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_BAG_L2/S1F8/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_BAG_L2/S1F2/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_BAG_L2/S1F3/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_BAG_L2/S1F6/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_BAG_L2/S1F4/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_BAG_L2/S1F7/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_BAG_L2/S1F1/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_BAG_L2/S1F5/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_r131_BAG_L1/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_r131_BAG_L1/S1F8/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_r131_BAG_L1/S1F2/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_r131_BAG_L1/utils/model_template.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_r131_BAG_L1/utils/oof.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_r131_BAG_L1/S1F3/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_r131_BAG_L1/S1F6/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_r131_BAG_L1/S1F4/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_r131_BAG_L1/S1F7/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_r131_BAG_L1/S1F1/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBM_r131_BAG_L1/S1F5/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMXT_BAG_L1/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMXT_BAG_L1/S1F8/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMXT_BAG_L1/S1F2/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMXT_BAG_L1/S1F3/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMXT_BAG_L1/S1F6/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMXT_BAG_L1/S1F4/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMXT_BAG_L1/S1F7/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMXT_BAG_L1/S1F1/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMXT_BAG_L1/S1F5/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_BAG_L1/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_BAG_L1/S1F8/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_BAG_L1/S1F2/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_BAG_L1/S1F3/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_BAG_L1/S1F6/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_BAG_L1/S1F4/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_BAG_L1/S1F7/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_BAG_L1/S1F1/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_BAG_L1/S1F5/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/WeightedEnsemble_L2/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMLarge_BAG_L2/S1F8/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMLarge_BAG_L2/S1F2/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMLarge_BAG_L2/S1F3/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMLarge_BAG_L2/S1F6/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMLarge_BAG_L2/S1F4/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMLarge_BAG_L2/S1F7/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMLarge_BAG_L2/S1F1/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/LightGBMLarge_BAG_L2/S1F5/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_BAG_L2/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_BAG_L2/S1F8/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_BAG_L2/S1F2/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_BAG_L2/S1F3/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_BAG_L2/S1F6/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_BAG_L2/S1F4/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_BAG_L2/S1F7/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_BAG_L2/S1F1/model.pkl\n",
      "/kaggle/input/catboost-xgboost-best-score/AutogluonModels/ag-20240929_150702/models/CatBoost_BAG_L2/S1F5/model.pkl\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd45d88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T21:33:16.529501Z",
     "iopub.status.busy": "2024-09-29T21:33:16.527816Z",
     "iopub.status.idle": "2024-09-29T21:40:06.914599Z",
     "shell.execute_reply": "2024-09-29T21:40:06.911909Z"
    },
    "papermill": {
     "duration": 410.399396,
     "end_time": "2024-09-29T21:40:06.918187",
     "exception": false,
     "start_time": "2024-09-29T21:33:16.518791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autogluon\r\n",
      "  Downloading autogluon-1.1.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting tbb\r\n",
      "  Downloading tbb-2021.13.1-py2.py3-none-manylinux1_x86_64.whl.metadata (1.0 kB)\r\n",
      "Collecting autogluon.core==1.1.1 (from autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading autogluon.core-1.1.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting autogluon.features==1.1.1 (from autogluon)\r\n",
      "  Downloading autogluon.features-1.1.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting autogluon.tabular==1.1.1 (from autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading autogluon.tabular-1.1.1-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting autogluon.multimodal==1.1.1 (from autogluon)\r\n",
      "  Downloading autogluon.multimodal-1.1.1-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting autogluon.timeseries==1.1.1 (from autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading autogluon.timeseries-1.1.1-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting numpy<1.29,>=1.21 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting scipy<1.13,>=1.5.4 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting scikit-learn<1.4.1,>=1.3.0 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Collecting networkx<4,>=3.0 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Collecting pandas<2.3.0,>=2.0.0 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting tqdm<5,>=4.38 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting requests (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\r\n",
      "Collecting matplotlib (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Collecting boto3<2,>=1.10 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading boto3-1.35.29-py3-none-any.whl.metadata (6.6 kB)\r\n",
      "Collecting autogluon.common==1.1.1 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading autogluon.common-1.1.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting ray<2.11,>=2.10.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\r\n",
      "Collecting hyperopt<0.2.8,>=0.2.7 (from autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Collecting Pillow<11,>=10.0.1 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\r\n",
      "Collecting torch<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\r\n",
      "Collecting lightning<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading lightning-2.3.3-py3-none-any.whl.metadata (35 kB)\r\n",
      "Collecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting accelerate<0.22.0,>=0.21.0 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\r\n",
      "Collecting jsonschema<4.22,>=4.18 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\r\n",
      "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25hCollecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\r\n",
      "Collecting timm<0.10.0,>=0.9.5 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading timm-0.9.16-py3-none-any.whl.metadata (38 kB)\r\n",
      "Collecting torchvision<0.19.0,>=0.16.0 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\r\n",
      "Collecting scikit-image<0.21.0,>=0.19.1 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\r\n",
      "Collecting text-unidecode<1.4,>=1.3 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Collecting torchmetrics<1.3.0,>=1.2.0 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading torchmetrics-1.2.1-py3-none-any.whl.metadata (20 kB)\r\n",
      "Collecting nptyping<2.5.0,>=1.4.4 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nptyping-2.4.1-py3-none-any.whl.metadata (7.7 kB)\r\n",
      "Collecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)\r\n",
      "Collecting pytorch-metric-learning<2.4,>=1.3.0 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl.metadata (17 kB)\r\n",
      "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\r\n",
      "Collecting nltk<4.0.0,>=3.4.5 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\r\n",
      "Collecting defusedxml<0.7.2,>=0.7.1 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\r\n",
      "Collecting jinja2<3.2,>=3.0.3 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Collecting tensorboard<3,>=2.9 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Collecting pytesseract<0.3.11,>=0.3.9 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting nvidia-ml-py3==7.352.0 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\r\n",
      "Collecting xgboost<2.1,>=1.6 (from autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\r\n",
      "Collecting fastai<2.8,>=2.3.1 (from autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading fastai-2.7.17-py3-none-any.whl.metadata (9.1 kB)\r\n",
      "Collecting lightgbm<4.4,>=3.3 (from autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading lightgbm-4.3.0-py3-none-manylinux_2_28_x86_64.whl.metadata (19 kB)\r\n",
      "Collecting catboost<1.3,>=1.1 (from autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\r\n",
      "Collecting joblib<2,>=1.1 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\r\n",
      "Collecting pytorch-lightning<2.4,>=2.2 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading pytorch_lightning-2.3.3-py3-none-any.whl.metadata (21 kB)\r\n",
      "Collecting gluonts==0.15.1 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading gluonts-0.15.1-py3-none-any.whl.metadata (9.9 kB)\r\n",
      "Collecting statsforecast<1.5,>=1.4.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading statsforecast-1.4.0-py3-none-any.whl.metadata (19 kB)\r\n",
      "Collecting mlforecast<0.10.1,>=0.10.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading mlforecast-0.10.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting utilsforecast<0.0.11,>=0.0.10 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading utilsforecast-0.0.10-py3-none-any.whl.metadata (7.0 kB)\r\n",
      "Collecting orjson~=3.9 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting optimum<1.19,>=1.17 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading optimum-1.18.1-py3-none-any.whl.metadata (18 kB)\r\n",
      "Collecting psutil<6,>=5.7.3 (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\r\n",
      "Collecting setuptools (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading setuptools-75.1.0-py3-none-any.whl.metadata (6.9 kB)\r\n",
      "Collecting pydantic<3,>=1.7 (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting toolz~=0.10 (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Collecting typing-extensions~=4.0 (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Collecting packaging>=20.0 (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Collecting pyyaml (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\r\n",
      "Collecting botocore<1.36.0,>=1.35.29 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading botocore-1.35.29-py3-none-any.whl.metadata (5.6 kB)\r\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\r\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Collecting graphviz (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting plotly (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading plotly-5.24.1-py3-none-any.whl.metadata (7.3 kB)\r\n",
      "Collecting six (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\r\n",
      "Collecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\r\n",
      "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting xxhash (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\r\n",
      "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting huggingface-hub>=0.7.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading huggingface_hub-0.25.1-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting pip (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading pip-24.2-py3-none-any.whl.metadata (3.6 kB)\r\n",
      "Collecting fastdownload<2,>=0.0.5 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading fastdownload-0.0.7-py3-none-any.whl.metadata (5.5 kB)\r\n",
      "Collecting fastcore<1.8,>=1.5.29 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading fastcore-1.7.10-py3-none-any.whl.metadata (3.5 kB)\r\n",
      "Collecting fastprogress>=0.2.4 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading fastprogress-1.0.3-py3-none-any.whl.metadata (5.6 kB)\r\n",
      "Collecting spacy<4 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading spacy-3.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\r\n",
      "Collecting future (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\r\n",
      "Collecting cloudpickle (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\r\n",
      "Collecting py4j (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Collecting MarkupSafe>=2.0 (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\r\n",
      "Collecting attrs>=22.2.0 (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Collecting referencing>=0.28.4 (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading rpds_py-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\r\n",
      "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\r\n",
      "Collecting numba (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\r\n",
      "Collecting window-ops (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Collecting gdown>=4.0.0 (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\r\n",
      "Collecting click (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Collecting regex>=2021.8.3 (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting colorama (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\r\n",
      "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\r\n",
      "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\r\n",
      "Collecting rich (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading rich-13.8.1-py3-none-any.whl.metadata (18 kB)\r\n",
      "Collecting tabulate (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\r\n",
      "Collecting coloredlogs (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting sympy (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting onnx (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\r\n",
      "Collecting onnxruntime>=1.11.0 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\r\n",
      "Collecting protobuf>=3.20.1 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading protobuf-5.28.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\r\n",
      "Collecting python-dateutil>=2.8.2 (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\r\n",
      "Collecting pytz>=2020.1 (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\r\n",
      "Collecting tzdata>=2022.7 (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Collecting filelock (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\r\n",
      "Collecting aiosignal (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\r\n",
      "Collecting frozenlist (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Collecting aiohttp>=3.7 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading aiohttp-3.10.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\r\n",
      "Collecting aiohttp-cors (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\r\n",
      "Collecting colorful (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\r\n",
      "Collecting py-spy>=0.2.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\r\n",
      "Collecting opencensus (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting prometheus-client>=0.7.1 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading prometheus_client-0.21.0-py3-none-any.whl.metadata (1.8 kB)\r\n",
      "Collecting smart-open (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading smart_open-7.0.4-py3-none-any.whl.metadata (23 kB)\r\n",
      "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading virtualenv-20.26.6-py3-none-any.whl.metadata (4.5 kB)\r\n",
      "Collecting grpcio>=1.42.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading grpcio-1.66.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\r\n",
      "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\r\n",
      "Collecting pyarrow>=6.0.1 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\r\n",
      "Collecting charset-normalizer<4,>=2 (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\r\n",
      "Collecting idna<4,>=2.5 (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Collecting certifi>=2017.4.17 (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Collecting imageio>=2.4.1 (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading imageio-2.35.1-py3-none-any.whl.metadata (4.9 kB)\r\n",
      "Collecting tifffile>=2019.7.26 (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading tifffile-2024.9.20-py3-none-any.whl.metadata (32 kB)\r\n",
      "Collecting PyWavelets>=1.1.1 (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\r\n",
      "Collecting lazy_loader>=0.1 (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\r\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn<1.4.1,>=1.3.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting statsmodels>=0.13.2 (from statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading statsmodels-0.14.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\r\n",
      "Collecting absl-py>=0.4 (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting markdown>=2.6.8 (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\r\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\r\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "Collecting safetensors (from timm<0.10.0,>=0.9.5->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting triton==2.3.1 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\r\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers<4.41.0,>=4.38.0->transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\r\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\r\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading contourpy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\r\n",
      "Collecting cycler>=0.10 (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading fonttools-4.54.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (163 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.7/163.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\r\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading aiohappyeyeballs-2.4.2-py3-none-any.whl.metadata (6.0 kB)\r\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\r\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading yarl-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0 (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\r\n",
      "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting beautifulsoup4 (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba->mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\r\n",
      "Collecting flatbuffers (from onnxruntime>=1.11.0->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\r\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\r\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\r\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\r\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading murmurhash-1.0.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\r\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading cymem-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\r\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading preshed-3.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\r\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading thinc-8.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\r\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\r\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\r\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\r\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\r\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading typer-0.12.5-py3-none-any.whl.metadata (15 kB)\r\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading langcodes-3.4.1-py3-none-any.whl.metadata (29 kB)\r\n",
      "Collecting patsy>=0.5.6 (from statsmodels>=0.13.2->statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\r\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading distlib-0.3.8-py2.py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Collecting platformdirs<5,>=3.9.1 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading platformdirs-4.3.6-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\r\n",
      "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\r\n",
      "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\r\n",
      "Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading google_api_core-2.20.0-py3-none-any.whl.metadata (2.7 kB)\r\n",
      "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\r\n",
      "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting tenacity>=6.2.0 (from plotly->catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\r\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\r\n",
      "Collecting pygments<3.0.0,>=2.13.0 (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting wrapt (from smart-open->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\r\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\r\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Collecting google-auth<3.0.dev0,>=2.14.1 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading google_auth-2.35.0-py2.py3-none-any.whl.metadata (4.7 kB)\r\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading language_data-1.2.0-py3-none-any.whl.metadata (4.3 kB)\r\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading blis-0.7.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\r\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\r\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\r\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading cloudpathlib-0.19.0-py3-none-any.whl.metadata (14 kB)\r\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\r\n",
      "Collecting filelock (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading oss2-2.17.0.tar.gz (259 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting pytz>=2020.1 (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\r\n",
      "INFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "INFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\r\n",
      "  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\r\n",
      "  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\r\n",
      "  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\r\n",
      "  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\r\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\r\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\r\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\r\n",
      "Collecting marisa-trie>=0.7.7 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading marisa_trie-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\r\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\r\n",
      "Downloading autogluon-1.1.1-py3-none-any.whl (9.7 kB)\r\n",
      "Downloading autogluon.core-1.1.1-py3-none-any.whl (234 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.8/234.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading autogluon.features-1.1.1-py3-none-any.whl (63 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading autogluon.multimodal-1.1.1-py3-none-any.whl (427 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.0/428.0 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading autogluon.tabular-1.1.1-py3-none-any.whl (312 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.1/312.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading autogluon.timeseries-1.1.1-py3-none-any.whl (148 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.2/148.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading autogluon.common-1.1.1-py3-none-any.whl (64 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading gluonts-0.15.1-py3-none-any.whl (1.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tbb-2021.13.1-py2.py3-none-manylinux1_x86_64.whl (5.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading accelerate-0.21.0-py3-none-any.whl (244 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading boto3-1.35.29-py3-none-any.whl (139 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\r\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fastai-2.7.17-py3-none-any.whl (234 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.5/234.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jinja2-3.1.4-py3-none-any.whl (133 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading lightgbm-4.3.0-py3-none-manylinux_2_28_x86_64.whl (3.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading lightning-2.3.3-py3-none-any.whl (808 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.5/808.5 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mlforecast-0.10.0-py3-none-any.whl (47 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading networkx-3.3-py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nptyping-2.4.1-py3-none-any.whl (36 kB)\r\n",
      "Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading optimum-1.18.1-py3-none-any.whl (410 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.0/410.0 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\r\n",
      "Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\r\n",
      "Downloading pytorch_lightning-2.3.3-py3-none-any.whl (812 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.3/812.3 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pytorch_metric_learning-2.3.0-py3-none-any.whl (115 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl (65.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading statsforecast-1.4.0-py3-none-any.whl (91 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading timm-0.9.16-py3-none-any.whl (2.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading utilsforecast-0.0.10-py3-none-any.whl (30 kB)\r\n",
      "Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl (297.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading aiohttp-3.10.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\r\n",
      "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading botocore-1.35.29-py3-none-any.whl (12.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading certifi-2024.8.30-py3-none-any.whl (167 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.1/142.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading contourpy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\r\n",
      "Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fastcore-1.7.10-py3-none-any.whl (80 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.1/80.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fastdownload-0.0.7-py3-none-any.whl (12 kB)\r\n",
      "Downloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\r\n",
      "Downloading fonttools-4.54.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\r\n",
      "Downloading grpcio-1.66.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading huggingface_hub-0.25.1-py3-none-any.whl (436 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.4/436.4 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading imageio-2.35.1-py3-none-any.whl (315 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.4/315.4 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\r\n",
      "Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\r\n",
      "Downloading kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading lazy_loader-0.4-py3-none-any.whl (12 kB)\r\n",
      "Downloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\r\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\r\n",
      "Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.0/378.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pip-24.2-py3-none-any.whl (1.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading prometheus_client-0.21.0-py3-none-any.whl (54 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading protobuf-5.28.2-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.2/751.2 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading referencing-0.35.1-py3-none-any.whl (26 kB)\r\n",
      "Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.7/782.7 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rpds_py-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (354 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.8/354.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading setuptools-75.1.0-py3-none-any.whl (1.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading six-1.16.0-py2.py3-none-any.whl (11 kB)\r\n",
      "Downloading spacy-3.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading statsmodels-0.14.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\r\n",
      "Downloading tifffile-2024.9.20-py3-none-any.whl (228 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.2/228.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading toolz-0.12.1-py3-none-any.whl (56 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\r\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading urllib3-2.2.3-py3-none-any.whl (126 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading virtualenv-20.26.6-py3-none-any.whl (6.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading filelock-3.16.1-py3-none-any.whl (16 kB)\r\n",
      "Downloading werkzeug-3.0.4-py3-none-any.whl (227 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\r\n",
      "Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\r\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\r\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading future-1.0.0-py3-none-any.whl (491 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading graphviz-0.20.3-py3-none-any.whl (47 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\r\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\r\n",
      "Downloading plotly-5.24.1-py3-none-any.whl (19.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rich-13.8.1-py3-none-any.whl (241 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.6/241.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading smart_open-7.0.4-py3-none-any.whl (61 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\r\n",
      "Downloading window_ops-0.0.15-py3-none-any.whl (15 kB)\r\n",
      "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.4.2-py3-none-any.whl (14 kB)\r\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\r\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\r\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\r\n",
      "Downloading cymem-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (46 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading google_api_core-2.20.0-py3-none-any.whl (142 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.2/142.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langcodes-3.4.1-py3-none-any.whl (182 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading murmurhash-1.0.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\r\n",
      "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\r\n",
      "Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.9/233.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading platformdirs-4.3.6-py3-none-any.whl (18 kB)\r\n",
      "Downloading preshed-3.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (156 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.9/156.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\r\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\r\n",
      "Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.0/493.0 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tenacity-9.0.0-py3-none-any.whl (28 kB)\r\n",
      "Downloading thinc-8.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.4/922.4 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading typer-0.12.5-py3-none-any.whl (47 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading wasabi-1.1.3-py3-none-any.whl (27 kB)\r\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading yarl-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (447 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.9/447.9 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\r\n",
      "Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl (19.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading openxlab-0.0.11-py3-none-any.whl (55 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\r\n",
      "Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading blis-0.7.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading cloudpathlib-0.19.0-py3-none-any.whl (49 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\r\n",
      "Downloading google_auth-2.35.0-py2.py3-none-any.whl (208 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.0/209.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.9/220.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading language_data-1.2.0-py3-none-any.whl (5.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\r\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading PySocks-1.7.1-py3-none-any.whl (16 kB)\r\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\r\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\r\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\r\n",
      "Downloading marisa_trie-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rsa-4.9-py3-none-any.whl (34 kB)\r\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: nvidia-ml-py3, antlr4-python3-runtime, seqeval\r\n",
      "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19172 sha256=ba86f7f4765d126874e403ee03041d7aa77fc03a0a5c2c913885076240f89bf6\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/d8/c0/46899f8be7a75a2ffd197a23c8797700ea858b9b34819fbf9e\r\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=17c10b60bf3d9ab04729b35bca34dd4fd87faa4dfedee05b0b9e882d7670d2b9\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\r\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=f298ea4240594f9fafd24f941cacb4b4c7d1d2105f094f205279a9a17b4b81c8\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\r\n",
      "Successfully built nvidia-ml-py3 antlr4-python3-runtime seqeval\r\n",
      "Installing collected packages: text-unidecode, tbb, sentencepiece, pytz, py4j, py-spy, opencensus-context, nvidia-ml-py3, mpmath, flatbuffers, distlib, cymem, colorful, antlr4-python3-runtime, xxhash, wrapt, wasabi, urllib3, tzdata, typing-extensions, tqdm, toolz, threadpoolctl, tensorboard-data-server, tenacity, tabulate, sympy, spacy-loggers, spacy-legacy, soupsieve, six, shellingham, setuptools, safetensors, rpds-py, regex, pyyaml, PySocks, pyparsing, pygments, pycryptodome, pyasn1, psutil, protobuf, prometheus-client, platformdirs, pip, Pillow, packaging, orjson, ordered-set, openxlab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, murmurhash, msgpack, mdurl, MarkupSafe, markdown, llvmlite, kiwisolver, joblib, jmespath, idna, humanfriendly, grpcio, graphviz, future, fsspec, frozenlist, fonttools, filelock, fastprogress, dill, defusedxml, cycler, colorama, cloudpickle, click, charset-normalizer, certifi, catalogue, cachetools, attrs, async-timeout, annotated-types, aiohappyeyeballs, absl-py, werkzeug, virtualenv, triton, tifffile, tensorboardX, srsly, smart-open, scipy, rsa, requests, referencing, PyWavelets, python-dateutil, pytesseract, pydantic-core, pyasn1-modules, pyarrow, proto-plus, preshed, plotly, pdf2image, patsy, onnx, omegaconf, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numba, nptyping, nltk, multiprocess, multidict, model-index, markdown-it-py, marisa-trie, lightning-utilities, lazy_loader, jinja2, imageio, googleapis-common-protos, fastcore, contourpy, coloredlogs, cloudpathlib, blis, beautifulsoup4, aiosignal, yarl, xgboost, window-ops, tensorboard, scikit-learn, scikit-image, rich, pydantic, pandas, onnxruntime, nvidia-cusolver-cu12, matplotlib, lightgbm, language-data, jsonschema-specifications, hyperopt, huggingface-hub, google-auth, fastdownload, botocore, utilsforecast, typer, torch, tokenizers, statsmodels, seqeval, s3transfer, opendatalab, langcodes, jsonschema, google-api-core, gluonts, gdown, confection, catboost, aiohttp, weasel, transformers, torchvision, torchmetrics, thinc, statsforecast, ray, pytorch-metric-learning, openmim, opencensus, nlpaug, mlforecast, boto3, aiohttp-cors, accelerate, timm, spacy, pytorch-lightning, datasets, autogluon.common, optimum, lightning, fastai, evaluate, autogluon.features, autogluon.core, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\r\n",
      "\u001b[33m  WARNING: The script tqdm is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script tabulate is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script isympy is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script pygmentize is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script openxlab is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script f2py is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script markdown_py is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script humanfriendly is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts futurize and pasteurize are installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts fonttools, pyftmerge, pyftsubset and ttx are installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script normalizer is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script virtualenv is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts lsm2bin, tiff2fsspec, tiffcomment and tifffile are installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts pyrsa-decrypt, pyrsa-encrypt, pyrsa-keygen, pyrsa-priv2pub, pyrsa-sign and pyrsa-verify are installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script pytesseract is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts backend-test-tools, check-model and check-node are installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script nltk is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script mi is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script markdown-it is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts imageio_download_bin and imageio_remove_bin are installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts py2pyi and replace_wildcards are installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script coloredlogs is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script tensorboard is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script onnxruntime_test is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script hyperopt-mongo-worker is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script huggingface-cli is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script typer is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script odl is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script jsonschema is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script gdown is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script weasel is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script transformers-cli is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts ray, rllib, serve and tune are installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script mim is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts accelerate, accelerate-config and accelerate-launch are installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script spacy is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script datasets-cli is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script optimum-cli is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts fabric and lightning are installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script configure_accelerate is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33m  WARNING: The script evaluate-cli is installed in '/root/.local/bin' which is not on PATH.\r\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "aiobotocore 2.15.0 requires botocore<1.35.17,>=1.35.16, but you have botocore 1.35.29 which is incompatible.\r\n",
      "albumentations 1.4.15 requires scikit-image>=0.21.0, but you have scikit-image 0.20.0 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 17.0.0 which is incompatible.\r\n",
      "beatrix-jupyterlab 2024.66.154055 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.5 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "bigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.3 which is incompatible.\r\n",
      "cesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "dataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.9.2 which is incompatible.\r\n",
      "google-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.20.0 which is incompatible.\r\n",
      "google-cloud-artifact-registry 1.11.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "google-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.20.0 which is incompatible.\r\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\r\n",
      "google-cloud-bigquery 2.34.4 requires protobuf<4.0.0dev,>=3.12.0, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "google-cloud-bigquery-connection 1.15.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "google-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "google-cloud-datastore 1.15.5 requires protobuf<4.0.0dev, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "google-cloud-dlp 3.18.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "google-cloud-functions 1.16.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "google-cloud-iam 2.15.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "google-cloud-monitoring 2.21.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "google-cloud-pubsub 2.21.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "google-cloud-recommendations-ai 0.7.1 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "google-cloud-resource-manager 1.12.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "google-cloud-spanner 3.47.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.2, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "google-cloud-vision 2.8.0 requires protobuf<4.0.0dev,>=3.19.0, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "grpc-google-iam-v1 0.12.7 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 17.0.0 which is incompatible.\r\n",
      "jupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "kfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "kfp 2.5.0 requires urllib3<2.0.0, but you have urllib3 2.2.3 which is incompatible.\r\n",
      "kfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "opentelemetry-proto 1.25.0 requires protobuf<5.0,>=3.19, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\r\n",
      "tensorboard-plugin-profile 2.15.1 requires protobuf<5.0.0dev,>=3.19.6, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "tensorflow 2.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "tensorflow 2.16.1 requires tensorboard<2.17,>=2.16, but you have tensorboard 2.18.0 which is incompatible.\r\n",
      "tensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "tensorflow-serving-api 2.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "tensorflow-transform 0.14.0 requires absl-py<2,>=0.7, but you have absl-py 2.1.0 which is incompatible.\r\n",
      "tensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 5.28.2 which is incompatible.\r\n",
      "torchaudio 2.4.0+cpu requires torch==2.4.0, but you have torch 2.3.1 which is incompatible.\r\n",
      "tsfresh 0.20.3 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.12.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 Pillow-10.4.0 PySocks-1.7.1 PyWavelets-1.7.0 absl-py-2.1.0 accelerate-0.21.0 aiohappyeyeballs-2.4.2 aiohttp-3.10.8 aiohttp-cors-0.7.0 aiosignal-1.3.1 annotated-types-0.7.0 antlr4-python3-runtime-4.9.3 async-timeout-4.0.3 attrs-24.2.0 autogluon-1.1.1 autogluon.common-1.1.1 autogluon.core-1.1.1 autogluon.features-1.1.1 autogluon.multimodal-1.1.1 autogluon.tabular-1.1.1 autogluon.timeseries-1.1.1 beautifulsoup4-4.12.3 blis-0.7.11 boto3-1.35.29 botocore-1.35.29 cachetools-5.5.0 catalogue-2.0.10 catboost-1.2.7 certifi-2024.8.30 charset-normalizer-3.3.2 click-8.1.7 cloudpathlib-0.19.0 cloudpickle-3.0.0 colorama-0.4.6 coloredlogs-15.0.1 colorful-0.5.6 confection-0.1.5 contourpy-1.3.0 cycler-0.12.1 cymem-2.0.8 datasets-3.0.1 defusedxml-0.7.1 dill-0.3.8 distlib-0.3.8 evaluate-0.4.3 fastai-2.7.17 fastcore-1.7.10 fastdownload-0.0.7 fastprogress-1.0.3 filelock-3.16.1 flatbuffers-24.3.25 fonttools-4.54.1 frozenlist-1.4.1 fsspec-2024.6.1 future-1.0.0 gdown-5.2.0 gluonts-0.15.1 google-api-core-2.20.0 google-auth-2.35.0 googleapis-common-protos-1.65.0 graphviz-0.20.3 grpcio-1.66.2 huggingface-hub-0.25.1 humanfriendly-10.0 hyperopt-0.2.7 idna-3.10 imageio-2.35.1 jinja2-3.1.4 jmespath-1.0.1 joblib-1.4.2 jsonschema-4.21.1 jsonschema-specifications-2023.12.1 kiwisolver-1.4.7 langcodes-3.4.1 language-data-1.2.0 lazy_loader-0.4 lightgbm-4.3.0 lightning-2.3.3 lightning-utilities-0.11.7 llvmlite-0.43.0 marisa-trie-1.2.0 markdown-3.7 markdown-it-py-3.0.0 matplotlib-3.9.2 mdurl-0.1.2 mlforecast-0.10.0 model-index-0.1.11 mpmath-1.3.0 msgpack-1.1.0 multidict-6.1.0 multiprocess-0.70.16 murmurhash-1.0.10 networkx-3.3 nlpaug-1.1.11 nltk-3.9.1 nptyping-2.4.1 numba-0.60.0 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-ml-py3-7.352.0 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.68 nvidia-nvtx-cu12-12.1.105 omegaconf-2.2.3 onnx-1.16.2 onnxruntime-1.19.2 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 optimum-1.18.1 ordered-set-4.1.0 orjson-3.10.7 packaging-24.1 pandas-2.2.3 patsy-0.5.6 pdf2image-1.17.0 pip-24.2 platformdirs-4.3.6 plotly-5.24.1 preshed-3.0.9 prometheus-client-0.21.0 proto-plus-1.24.0 protobuf-5.28.2 psutil-5.9.8 py-spy-0.3.14 py4j-0.10.9.7 pyarrow-17.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 pycryptodome-3.20.0 pydantic-2.9.2 pydantic-core-2.23.4 pygments-2.18.0 pyparsing-3.1.4 pytesseract-0.3.10 python-dateutil-2.9.0.post0 pytorch-lightning-2.3.3 pytorch-metric-learning-2.3.0 pytz-2024.2 pyyaml-6.0.2 ray-2.10.0 referencing-0.35.1 regex-2024.9.11 requests-2.32.3 rich-13.8.1 rpds-py-0.20.0 rsa-4.9 s3transfer-0.10.2 safetensors-0.4.5 scikit-image-0.20.0 scikit-learn-1.4.0 scipy-1.12.0 sentencepiece-0.2.0 seqeval-1.2.2 setuptools-75.1.0 shellingham-1.5.4 six-1.16.0 smart-open-7.0.4 soupsieve-2.6 spacy-3.7.6 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 statsforecast-1.4.0 statsmodels-0.14.3 sympy-1.13.3 tabulate-0.9.0 tbb-2021.13.1 tenacity-9.0.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorboardX-2.6.2.2 text-unidecode-1.3 thinc-8.2.5 threadpoolctl-3.5.0 tifffile-2024.9.20 timm-0.9.16 tokenizers-0.15.2 toolz-0.12.1 torch-2.3.1 torchmetrics-1.2.1 torchvision-0.18.1 tqdm-4.66.5 transformers-4.39.3 triton-2.3.1 typer-0.12.5 typing-extensions-4.12.2 tzdata-2024.2 urllib3-2.2.3 utilsforecast-0.0.10 virtualenv-20.26.6 wasabi-1.1.3 weasel-0.4.1 werkzeug-3.0.4 window-ops-0.0.15 wrapt-1.16.0 xgboost-2.0.3 xxhash-3.5.0 yarl-1.13.1\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U autogluon --ignore-installed tbb --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dfdf89f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T21:40:07.309200Z",
     "iopub.status.busy": "2024-09-29T21:40:07.308149Z",
     "iopub.status.idle": "2024-09-29T21:40:10.541500Z",
     "shell.execute_reply": "2024-09-29T21:40:10.540189Z"
    },
    "papermill": {
     "duration": 3.424536,
     "end_time": "2024-09-29T21:40:10.544734",
     "exception": false,
     "start_time": "2024-09-29T21:40:07.120198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import log_evaluation, early_stopping\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdde954",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T19:57:47.059412Z",
     "iopub.status.busy": "2024-09-29T19:57:47.058987Z",
     "iopub.status.idle": "2024-09-29T20:04:46.086559Z",
     "shell.execute_reply": "2024-09-29T20:04:46.084618Z",
     "shell.execute_reply.started": "2024-09-29T19:57:47.059361Z"
    },
    "papermill": {
     "duration": 0.201898,
     "end_time": "2024-09-29T21:40:10.938416",
     "exception": false,
     "start_time": "2024-09-29T21:40:10.736518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d651215",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T21:40:11.350309Z",
     "iopub.status.busy": "2024-09-29T21:40:11.349256Z",
     "iopub.status.idle": "2024-09-29T21:40:13.229767Z",
     "shell.execute_reply": "2024-09-29T21:40:13.227974Z"
    },
    "papermill": {
     "duration": 2.089876,
     "end_time": "2024-09-29T21:40:13.233548",
     "exception": false,
     "start_time": "2024-09-29T21:40:11.143672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/playground-series-s4e9/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/playground-series-s4e9/test.csv')\n",
    "Original = pd.read_csv('/kaggle/input/used-car-price-prediction-dataset/used_cars.csv')\n",
    "Original[['milage', 'price']] = Original[['milage', 'price']].map(\n",
    "    lambda x: int(''.join(re.findall(r'\\d+', x))))\n",
    "\n",
    "\n",
    "train.drop(columns=['id'], inplace=True)\n",
    "test.drop(columns=['id'], inplace=True)\n",
    "\n",
    "\n",
    "train = pd.concat([train, Original], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13ca5180",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T21:40:13.610449Z",
     "iopub.status.busy": "2024-09-29T21:40:13.609896Z",
     "iopub.status.idle": "2024-09-29T21:40:13.744663Z",
     "shell.execute_reply": "2024-09-29T21:40:13.743277Z"
    },
    "papermill": {
     "duration": 0.32749,
     "end_time": "2024-09-29T21:40:13.748117",
     "exception": false,
     "start_time": "2024-09-29T21:40:13.420627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(set(train['model'].unique()) - set(test['model'].unique()))\n",
    "train = train[~train['model'].isin(list(set(train['model'].unique()) - set(test['model'].unique())))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e04b5eaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T21:40:14.127672Z",
     "iopub.status.busy": "2024-09-29T21:40:14.127230Z",
     "iopub.status.idle": "2024-09-29T21:40:14.589944Z",
     "shell.execute_reply": "2024-09-29T21:40:14.588586Z"
    },
    "papermill": {
     "duration": 0.658291,
     "end_time": "2024-09-29T21:40:14.592928",
     "exception": false,
     "start_time": "2024-09-29T21:40:13.934637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_age_features(df):\n",
    "    current_year = 2024\n",
    "\n",
    "    df['Vehicle_Age'] = current_year - df['model_year']\n",
    "    \n",
    "    df['Mileage_per_Year'] = df['milage'] / df['Vehicle_Age']\n",
    "    df['milage_with_age'] =  df.groupby('Vehicle_Age')['milage'].transform('mean')\n",
    "    \n",
    "    df['Mileage_per_Year_with_age'] =  df.groupby('Vehicle_Age')['Mileage_per_Year'].transform('mean')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def segment_mileage(df):\n",
    "    def popka(milage):\n",
    "        if milage < 70000:\n",
    "            return 'Low'\n",
    "        elif milage < 150000:\n",
    "            return 'Medium'\n",
    "        elif milage < 190000:\n",
    "            return 'High'\n",
    "        else: return 'pizda'\n",
    "    df['popa'] = df['milage'].apply(popka)\n",
    "    return df\n",
    "    \n",
    "def extract_other_features(df):\n",
    "    \n",
    "    luxury_brands =  ['Bugatti', 'Lamborghini', 'Rolls-Royce', 'Bentley', 'McLaren', 'Ferrari','Aston']\n",
    "    df['Is_Luxury_Brand'] = df['brand'].apply(lambda x: 1 if x in luxury_brands else 0)\n",
    "\n",
    "    return df\n",
    "\n",
    "train = extract_age_features(train)\n",
    "test = extract_age_features(test)\n",
    "\n",
    "train = segment_mileage(train)\n",
    "test = segment_mileage(test)\n",
    "\n",
    "train = extract_other_features(train)\n",
    "test = extract_other_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "026aeab8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T21:40:14.963143Z",
     "iopub.status.busy": "2024-09-29T21:40:14.962675Z",
     "iopub.status.idle": "2024-09-29T21:40:15.627634Z",
     "shell.execute_reply": "2024-09-29T21:40:15.626136Z"
    },
    "papermill": {
     "duration": 0.854059,
     "end_time": "2024-09-29T21:40:15.630926",
     "exception": false,
     "start_time": "2024-09-29T21:40:14.776867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/playground-series-s4e9/train.csv\", index_col= 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45f065d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T21:40:16.010569Z",
     "iopub.status.busy": "2024-09-29T21:40:16.009967Z",
     "iopub.status.idle": "2024-09-29T21:40:19.290698Z",
     "shell.execute_reply": "2024-09-29T21:40:19.289204Z"
    },
    "papermill": {
     "duration": 3.474605,
     "end_time": "2024-09-29T21:40:19.294246",
     "exception": false,
     "start_time": "2024-09-29T21:40:15.819641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_to_match=['brand', 'model', 'model_year', 'fuel_type', 'engine',\n",
    "       'transmission', 'ext_col', 'int_col', 'accident', 'clean_title',\n",
    "        'Vehicle_Age', 'popa', 'Is_Luxury_Brand']\n",
    "\n",
    "intersection = pd.merge(train, test, how='inner',on=columns_to_match, indicator=True)\n",
    "\n",
    "# Оставляем только те строки, которые есть в обоих датафреймах\n",
    "intersection = intersection[intersection['_merge'] == 'both'].drop(columns='_merge')\n",
    "columns_to_match=['brand', 'model', 'model_year', 'fuel_type', 'engine',\n",
    "       'transmission', 'ext_col', 'int_col', 'accident', 'clean_title',\n",
    "        'Vehicle_Age', 'popa', 'Is_Luxury_Brand']\n",
    "#ищем дорогие тачки\n",
    "intersection = pd.merge(train, test, how='inner',on=columns_to_match, indicator=True)\n",
    "def update(df):\n",
    "    \n",
    "    t = 100\n",
    "    \n",
    "    cat_c = ['brand','model','fuel_type','engine','transmission','ext_col','int_col','accident','clean_title','popa',\n",
    "             \n",
    "            ]\n",
    "    re_ = ['model','engine','transmission','ext_col','int_col']\n",
    "    \n",
    "    for col in re_:\n",
    "        df.loc[df[col].value_counts(dropna=False)[df[col]].values < t, col] = \"noise\"\n",
    "        \n",
    "    for col in cat_c:\n",
    "        df[col] = df[col].fillna('missing')\n",
    "        df[col] = df[col].astype('category')\n",
    "        \n",
    "    return df\n",
    "\n",
    "train  = update(train)\n",
    "test   = update(test)\n",
    "\n",
    "X = train.drop('price', axis=1)\n",
    "y = train['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67f408ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T21:40:19.813219Z",
     "iopub.status.busy": "2024-09-29T21:40:19.809060Z",
     "iopub.status.idle": "2024-09-29T21:42:09.278827Z",
     "shell.execute_reply": "2024-09-29T21:42:09.277265Z"
    },
    "papermill": {
     "duration": 109.748684,
     "end_time": "2024-09-29T21:42:09.281949",
     "exception": false,
     "start_time": "2024-09-29T21:40:19.533265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_cols--------['brand', 'model', 'fuel_type', 'engine', 'transmission', 'ext_col', 'int_col', 'accident', 'clean_title', 'popa']\n",
      "Training fold 1/5 with LGBM\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1729\n",
      "[LightGBM] [Info] Number of data points in the train set: 154013, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 30775.000000\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[300]\ttrain's l1: 16404.3\tvalid's l1: 16781.3\n",
      "[600]\ttrain's l1: 16192.2\tvalid's l1: 16779\n",
      "Early stopping, best iteration is:\n",
      "[601]\ttrain's l1: 16190.1\tvalid's l1: 16778.2\n",
      "LGBM Fold RMSE: 67864.71192678237\n",
      "Training fold 2/5 with LGBM\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 154013, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 30825.000000\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[300]\ttrain's l1: 16327.8\tvalid's l1: 17109.5\n",
      "[600]\ttrain's l1: 16110\tvalid's l1: 17114.8\n",
      "Early stopping, best iteration is:\n",
      "[447]\ttrain's l1: 16216.7\tvalid's l1: 17107.8\n",
      "LGBM Fold RMSE: 72829.81241\n",
      "Training fold 3/5 with LGBM\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1729\n",
      "[LightGBM] [Info] Number of data points in the train set: 154014, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 30798.000000\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[300]\ttrain's l1: 16271.1\tvalid's l1: 17379.5\n",
      "Early stopping, best iteration is:\n",
      "[196]\ttrain's l1: 16390.9\tvalid's l1: 17373.9\n",
      "LGBM Fold RMSE: 79420.88214708812\n",
      "Training fold 4/5 with LGBM\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 154014, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 30798.000000\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[300]\ttrain's l1: 16320.2\tvalid's l1: 17130.4\n",
      "Early stopping, best iteration is:\n",
      "[269]\ttrain's l1: 16352.7\tvalid's l1: 17129.7\n",
      "LGBM Fold RMSE: 71581.7710343448\n",
      "Training fold 5/5 with LGBM\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1728\n",
      "[LightGBM] [Info] Number of data points in the train set: 154014, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 30934.500000\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[300]\ttrain's l1: 16299.3\tvalid's l1: 17235.4\n",
      "Early stopping, best iteration is:\n",
      "[221]\ttrain's l1: 16376.5\tvalid's l1: 17233\n",
      "LGBM Fold RMSE: 75814.78600578262\n",
      "Mean RMSE: 73502.39270479957\n",
      "Training fold 1/5 with LGBM\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1984\n",
      "[LightGBM] [Info] Number of data points in the train set: 154013, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 43952.378111\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttrain's l2: 5.07052e+09\tvalid's l2: 4.55699e+09\n",
      "LGBM Fold RMSE: 67505.46024147894\n",
      "Training fold 2/5 with LGBM\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1983\n",
      "[LightGBM] [Info] Number of data points in the train set: 154013, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 43926.443761\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttrain's l2: 4.8575e+09\tvalid's l2: 5.20812e+09\n",
      "LGBM Fold RMSE: 72167.33508801978\n",
      "Training fold 3/5 with LGBM\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1984\n",
      "[LightGBM] [Info] Number of data points in the train set: 154014, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 43804.659557\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttrain's l2: 4.49546e+09\tvalid's l2: 6.19671e+09\n",
      "LGBM Fold RMSE: 78719.17148013062\n",
      "Training fold 4/5 with LGBM\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1983\n",
      "[LightGBM] [Info] Number of data points in the train set: 154014, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 43871.331431\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttrain's l2: 4.84192e+09\tvalid's l2: 5.02035e+09\n",
      "LGBM Fold RMSE: 70854.40092062319\n",
      "Training fold 5/5 with LGBM\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1983\n",
      "[LightGBM] [Info] Number of data points in the train set: 154014, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 43916.133176\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttrain's l2: 4.69529e+09\tvalid's l2: 5.58013e+09\n",
      "LGBM Fold RMSE: 74700.24979200716\n",
      "Mean RMSE: 72789.32350445194\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>model_year</th>\n",
       "      <th>milage</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>engine</th>\n",
       "      <th>transmission</th>\n",
       "      <th>ext_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>accident</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Mileage_per_Year</th>\n",
       "      <th>milage_with_age</th>\n",
       "      <th>Mileage_per_Year_with_age</th>\n",
       "      <th>popa</th>\n",
       "      <th>Is_Luxury_Brand</th>\n",
       "      <th>LGBM_MAE</th>\n",
       "      <th>LGBM_MSE_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Land</td>\n",
       "      <td>noise</td>\n",
       "      <td>2015</td>\n",
       "      <td>98000</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>240.0HP 2.0L 4 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>6-Speed A/T</td>\n",
       "      <td>White</td>\n",
       "      <td>Beige</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9</td>\n",
       "      <td>10888.888889</td>\n",
       "      <td>81078.503981</td>\n",
       "      <td>9008.722665</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "      <td>16561.651566</td>\n",
       "      <td>3839.718614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Land</td>\n",
       "      <td>Rover Defender SE</td>\n",
       "      <td>2020</td>\n",
       "      <td>9142</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>395.0HP 3.0L Straight 6 Cylinder Engine Gasoli...</td>\n",
       "      <td>8-Speed A/T</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Black</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>2285.500000</td>\n",
       "      <td>34258.886442</td>\n",
       "      <td>8564.721611</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>57042.320947</td>\n",
       "      <td>15610.873177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ford</td>\n",
       "      <td>Expedition Limited</td>\n",
       "      <td>2022</td>\n",
       "      <td>28121</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>3.5L V6 24V PDI DOHC Twin Turbo</td>\n",
       "      <td>10-Speed Automatic</td>\n",
       "      <td>White</td>\n",
       "      <td>Ebony</td>\n",
       "      <td>None reported</td>\n",
       "      <td>missing</td>\n",
       "      <td>2</td>\n",
       "      <td>14060.500000</td>\n",
       "      <td>17877.043403</td>\n",
       "      <td>8938.521702</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>48870.687359</td>\n",
       "      <td>9517.211084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Audi</td>\n",
       "      <td>noise</td>\n",
       "      <td>2016</td>\n",
       "      <td>61258</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>2.0 Liter TFSI</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>noise</td>\n",
       "      <td>Black</td>\n",
       "      <td>None reported</td>\n",
       "      <td>missing</td>\n",
       "      <td>8</td>\n",
       "      <td>7657.250000</td>\n",
       "      <td>75999.679762</td>\n",
       "      <td>9499.959970</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>25378.794844</td>\n",
       "      <td>3452.569548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Audi</td>\n",
       "      <td>A6 2.0T Premium Plus</td>\n",
       "      <td>2018</td>\n",
       "      <td>59000</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>252.0HP 2.0L 4 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>A/T</td>\n",
       "      <td>Gray</td>\n",
       "      <td>Black</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>6</td>\n",
       "      <td>9833.333333</td>\n",
       "      <td>52105.532436</td>\n",
       "      <td>8684.255406</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>27080.066657</td>\n",
       "      <td>4590.180662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  brand                 model  model_year  milage fuel_type  \\\n",
       "0  Land                 noise        2015   98000  Gasoline   \n",
       "1  Land     Rover Defender SE        2020    9142    Hybrid   \n",
       "2  Ford    Expedition Limited        2022   28121  Gasoline   \n",
       "3  Audi                 noise        2016   61258  Gasoline   \n",
       "4  Audi  A6 2.0T Premium Plus        2018   59000  Gasoline   \n",
       "\n",
       "                                              engine        transmission  \\\n",
       "0       240.0HP 2.0L 4 Cylinder Engine Gasoline Fuel         6-Speed A/T   \n",
       "1  395.0HP 3.0L Straight 6 Cylinder Engine Gasoli...         8-Speed A/T   \n",
       "2                    3.5L V6 24V PDI DOHC Twin Turbo  10-Speed Automatic   \n",
       "3                                     2.0 Liter TFSI           Automatic   \n",
       "4       252.0HP 2.0L 4 Cylinder Engine Gasoline Fuel                 A/T   \n",
       "\n",
       "  ext_col int_col       accident clean_title  Vehicle_Age  Mileage_per_Year  \\\n",
       "0   White   Beige  None reported         Yes            9      10888.888889   \n",
       "1  Silver   Black  None reported         Yes            4       2285.500000   \n",
       "2   White   Ebony  None reported     missing            2      14060.500000   \n",
       "3   noise   Black  None reported     missing            8       7657.250000   \n",
       "4    Gray   Black  None reported         Yes            6       9833.333333   \n",
       "\n",
       "   milage_with_age  Mileage_per_Year_with_age    popa  Is_Luxury_Brand  \\\n",
       "0     81078.503981                9008.722665  Medium                0   \n",
       "1     34258.886442                8564.721611     Low                0   \n",
       "2     17877.043403                8938.521702     Low                0   \n",
       "3     75999.679762                9499.959970     Low                0   \n",
       "4     52105.532436                8684.255406     Low                0   \n",
       "\n",
       "       LGBM_MAE  LGBM_MSE_diff  \n",
       "0  16561.651566    3839.718614  \n",
       "1  57042.320947   15610.873177  \n",
       "2  48870.687359    9517.211084  \n",
       "3  25378.794844    3452.569548  \n",
       "4  27080.066657    4590.180662  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "\n",
    "callbacks = [log_evaluation(period=300), early_stopping(stopping_rounds=200)]\n",
    "\n",
    "cat_cols = train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(f\"cat_cols--------{cat_cols}\")\n",
    "\n",
    "\n",
    "def get_MAE_oof(df, target, lgb_params, cat_params=None, model_type='LGBM'):\n",
    "\n",
    "    \n",
    "    oof_predictions = np.zeros(len(df))\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    models = []\n",
    "    rmse_scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n",
    "        print(f\"Training fold {fold + 1}/{5} with {model_type}\")\n",
    "\n",
    "        X_train, X_val = df.iloc[train_idx], df.iloc[val_idx]\n",
    "        y_train, y_val = target.iloc[train_idx], target.iloc[val_idx]\n",
    "\n",
    "        if model_type == 'LGBM':\n",
    "            train_data = lgb.Dataset(X_train, label=y_train)\n",
    "            val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "            \n",
    "            model = lgb.train(\n",
    "                lgb_params,\n",
    "                train_data,\n",
    "                valid_sets=[train_data, val_data],\n",
    "                valid_names=['train', 'valid'],\n",
    "                callbacks=callbacks    \n",
    "            )\n",
    "        \n",
    "        elif model_type == 'CAT':\n",
    "            train_data = Pool(data=X_train, label=y_train , cat_features=cat_cols)\n",
    "            val_data = Pool(data=X_val, label=y_val , cat_features=cat_cols )\n",
    "            \n",
    "            model = CatBoostRegressor(**cat_params)\n",
    "            model.fit(train_data, eval_set=val_data, verbose=150, early_stopping_rounds=200)\n",
    "        \n",
    "        models.append(model)\n",
    "        \n",
    "        if model_type == 'LGBM':\n",
    "            pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "        elif model_type == 'CAT':\n",
    "            pred = model.predict(X_val)\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(y_val, pred))\n",
    "        rmse_scores.append(rmse)\n",
    "\n",
    "        print(f'{model_type} Fold RMSE: {rmse}')\n",
    "        \n",
    "        oof_predictions[val_idx] = pred\n",
    "        \n",
    "    print(f'Mean RMSE: {np.mean(rmse_scores)}')\n",
    "    return oof_predictions, models\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lgb_params = {\n",
    "    'objective': 'MAE',\n",
    "    'n_estimators': 1000,\n",
    "    'random_state': 1,\n",
    "}\n",
    "\n",
    "oof_predictions_lgbm, models_lgbm = get_MAE_oof(X, y, lgb_params, model_type='LGBM')\n",
    "X['LGBM_MAE'] = oof_predictions_lgbm\n",
    "\n",
    "\n",
    "LGBM_preds = np.zeros(len(test))\n",
    "for model in models_lgbm:\n",
    "    LGBM_preds += model.predict(test) / len(models_lgbm)\n",
    "test['LGBM_MAE'] = LGBM_preds\n",
    "\n",
    "\n",
    "\n",
    "lgb_params = {\n",
    "    'objective': 'MSE',\n",
    "    'n_estimators': 1000,\n",
    "    'random_state': 1,\n",
    "}\n",
    "\n",
    "oof_predictions_lgbm, models_lgbm = get_MAE_oof(X, y, lgb_params, model_type='LGBM')\n",
    "\n",
    "X['LGBM_MSE_diff'] = oof_predictions_lgbm - X['LGBM_MAE']\n",
    "\n",
    "\n",
    "LGBM_preds = np.zeros(len(test))\n",
    "for model in models_lgbm:\n",
    "    LGBM_preds += model.predict(test) / len(models_lgbm)\n",
    "test['LGBM_MSE_diff'] = LGBM_preds - test['LGBM_MAE']\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4460c6be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T21:42:09.670126Z",
     "iopub.status.busy": "2024-09-29T21:42:09.669587Z",
     "iopub.status.idle": "2024-09-29T22:42:47.991115Z",
     "shell.execute_reply": "2024-09-29T22:42:47.989268Z"
    },
    "papermill": {
     "duration": 3638.519661,
     "end_time": "2024-09-29T22:42:47.995285",
     "exception": false,
     "start_time": "2024-09-29T21:42:09.475624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240929_214209\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Jun 27 20:43:36 UTC 2024\n",
      "CPU Count:          4\n",
      "Memory Avail:       29.98 GB / 31.36 GB (95.6%)\n",
      "Disk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "2024-09-29 21:42:10,156\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2024-09-29 21:42:15,510\tINFO worker.py:1743 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"AutogluonModels/ag-20240929_214209/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Beginning AutoGluon training ... Time limit = 888s\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m AutoGluon will save models to \"AutogluonModels/ag-20240929_214209/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Train Data Rows:    171126\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Train Data Columns: 19\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Label Column:       price\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Problem Type:       regression\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \tAvailable Memory:                    30198.96 MB\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \tTrain Data (Original)  Memory Usage: 13.79 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t\t('category', []) : 10 | ['brand', 'model', 'fuel_type', 'engine', 'transmission', ...]\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t\t('float', [])    :  5 | ['Mileage_per_Year', 'milage_with_age', 'Mileage_per_Year_with_age', 'LGBM_MAE', 'LGBM_MSE_diff']\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t\t('int', [])      :  4 | ['model_year', 'milage', 'Vehicle_Age', 'Is_Luxury_Brand']\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t\t('category', [])  : 9 | ['brand', 'model', 'fuel_type', 'engine', 'transmission', ...]\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t\t('float', [])     : 5 | ['Mileage_per_Year', 'milage_with_age', 'Mileage_per_Year_with_age', 'LGBM_MAE', 'LGBM_MSE_diff']\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t\t('int', [])       : 3 | ['model_year', 'milage', 'Vehicle_Age']\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t\t('int', ['bool']) : 2 | ['clean_title', 'Is_Luxury_Brand']\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t0.7s = Fit runtime\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t19 features in original data used to generate 19 features in processed data.\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \tTrain Data (Processed) Memory Usage: 12.57 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Data preprocessing and feature engineering runtime = 0.76s ...\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Included models: ['GBM', 'CAT'] (Specified by `included_model_types`, all other model types will be skipped)\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Fitting 36 L1 models ...\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 591.57s of the 887.57s of remaining time.\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.31%)\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t-73608.2591\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t78.13s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t5.35s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 497.31s of the 793.31s of remaining time.\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.31%)\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t-73886.2991\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t69.57s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t3.71s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 412.37s of the 708.37s of remaining time.\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.32%)\n",
      "\u001b[36m(_ray_fit pid=1355)\u001b[0m TBB Warning: The number of workers is currently limited to 0. The request for 3 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\n",
      "\u001b[36m(_ray_fit pid=1355)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=1355)\u001b[0m \tRan out of time, early stopping on iteration 53.\n",
      "\u001b[36m(_ray_fit pid=1356)\u001b[0m TBB Warning: The number of workers is currently limited to 0. The request for 3 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1356)\u001b[0m \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1354)\u001b[0m \tRan out of time, early stopping on iteration 54.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1479)\u001b[0m TBB Warning: The number of workers is currently limited to 0. The request for 3 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\n",
      "\u001b[36m(_ray_fit pid=1479)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=1511)\u001b[0m TBB Warning: The number of workers is currently limited to 0. The request for 3 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\n",
      "\u001b[36m(_ray_fit pid=1511)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=1511)\u001b[0m \tRan out of time, early stopping on iteration 53.\n",
      "\u001b[36m(_ray_fit pid=1553)\u001b[0m TBB Warning: The number of workers is currently limited to 0. The request for 3 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1553)\u001b[0m \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1479)\u001b[0m \tRan out of time, early stopping on iteration 52.\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t-73633.0056\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t345.77s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t1.6s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 50.9s of the 346.9s of remaining time.\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.37%)\n",
      "\u001b[36m(_ray_fit pid=1728)\u001b[0m \tRan out of time, early stopping on iteration 73. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1728)\u001b[0m \t[62]\tvalid_set's rmse: 73407\n",
      "\u001b[36m(_ray_fit pid=1553)\u001b[0m \tRan out of time, early stopping on iteration 54.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1846)\u001b[0m \tRan out of time, early stopping on iteration 63. Best iteration is:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1846)\u001b[0m \t[59]\tvalid_set's rmse: 66663.3\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t-74461.0098\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t75.18s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t7.61s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 252.89s of remaining time.\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.52, 'CatBoost_BAG_L1': 0.44, 'LightGBM_BAG_L1': 0.04}\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t-73536.5486\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t1.5s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Included models: ['GBM', 'CAT'] (Specified by `included_model_types`, all other model types will be skipped)\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Fitting 36 L2 models ...\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 251.21s of the 250.97s of remaining time.\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.38%)\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t-73633.0165\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t80.36s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t5.57s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 152.06s of the 151.83s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=1900)\u001b[0m \tRan out of time, early stopping on iteration 73. Best iteration is:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1900)\u001b[0m \t[60]\tvalid_set's rmse: 85642.5\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.37%)\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t-73875.3636\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t76.74s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t3.39s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 56.61s of the 56.39s of remaining time.\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.39%)\n",
      "\u001b[36m(_ray_fit pid=2718)\u001b[0m TBB Warning: The number of workers is currently limited to 0. The request for 3 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\n",
      "\u001b[36m(_ray_fit pid=2718)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=2718)\u001b[0m \tRan out of time, early stopping on iteration 1.\n",
      "\u001b[36m(_ray_fit pid=2717)\u001b[0m TBB Warning: The number of workers is currently limited to 0. The request for 3 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2717)\u001b[0m \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2717)\u001b[0m \tRan out of time, early stopping on iteration 1.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2841)\u001b[0m TBB Warning: The number of workers is currently limited to 0. The request for 3 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\n",
      "\u001b[36m(_ray_fit pid=2841)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=2879)\u001b[0m TBB Warning: The number of workers is currently limited to 0. The request for 3 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\n",
      "\u001b[36m(_ray_fit pid=2879)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=2887)\u001b[0m \tRan out of time, early stopping on iteration 1.\n",
      "\u001b[36m(_ray_fit pid=2888)\u001b[0m TBB Warning: The number of workers is currently limited to 0. The request for 3 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2888)\u001b[0m \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2888)\u001b[0m \tRan out of time, early stopping on iteration 1.\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t-79153.9718\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t61.08s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t7.82s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -24.25s of remaining time.\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.44, 'CatBoost_BAG_L1': 0.4, 'LightGBMXT_BAG_L2': 0.12, 'LightGBM_BAG_L1': 0.04}\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t-73534.3369\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t3.25s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m AutoGluon training complete, total runtime = 916.12s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 897.0 rows/s (21391 batch size)\n",
      "\u001b[36m(_ray_fit pid=2879)\u001b[0m \tRan out of time, early stopping on iteration 1.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240929_214209/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m TBB Warning: The number of workers is currently limited to 0. The request for 3 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\n",
      "\u001b[36m(_dystack pid=387)\u001b[0m \n",
      "\u001b[36m(_dystack pid=387)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                  model  score_holdout     score_val              eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   WeightedEnsemble_L3  -64454.158229 -73534.336873  root_mean_squared_error        7.014560      23.881569  652.265826                 0.006686                0.038932           3.251465            3       True          9\n",
      "1     LightGBMXT_BAG_L2  -64456.586396 -73633.016469  root_mean_squared_error        7.007874      23.842637  649.014361                 0.969626                5.572306          80.362485            2       True          6\n",
      "2   WeightedEnsemble_L2  -64460.170172 -73536.548574  root_mean_squared_error        4.888208      10.697750  494.971823                 0.007206                0.036549           1.496488            2       True          5\n",
      "3     LightGBMXT_BAG_L1  -64478.710954 -73608.259149  root_mean_squared_error        3.184800       5.350428   78.134722                 3.184800                5.350428          78.134722            1       True          1\n",
      "4       CatBoost_BAG_L1  -64589.964092 -73633.005591  root_mean_squared_error        0.974198       1.598005  345.769760                 0.974198                1.598005         345.769760            1       True          3\n",
      "5       LightGBM_BAG_L2  -64691.571426 -73875.363568  root_mean_squared_error        6.718236      21.658932  645.396302                 0.679988                3.388602          76.744425            2       True          7\n",
      "6       LightGBM_BAG_L1  -64741.972057 -73886.299060  root_mean_squared_error        0.722004       3.712768   69.570853                 0.722004                3.712768          69.570853            1       True          2\n",
      "7  LightGBMLarge_BAG_L1  -65091.494490 -74461.009848  root_mean_squared_error        1.157245       7.609130   75.176542                 1.157245                7.609130          75.176542            1       True          4\n",
      "8       CatBoost_BAG_L2  -70916.557717 -79153.971798  root_mean_squared_error        6.192924      26.091594  629.735313                 0.154677                7.821263          61.083436            2       True          8\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t941s\t = DyStack   runtime |\t2659s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 2659s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240929_214209\"\n",
      "Train Data Rows:    192517\n",
      "Train Data Columns: 19\n",
      "Label Column:       price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29995.66 MB\n",
      "\tTrain Data (Original)  Memory Usage: 15.51 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 10 | ['brand', 'model', 'fuel_type', 'engine', 'transmission', ...]\n",
      "\t\t('float', [])    :  5 | ['Mileage_per_Year', 'milage_with_age', 'Mileage_per_Year_with_age', 'LGBM_MAE', 'LGBM_MSE_diff']\n",
      "\t\t('int', [])      :  4 | ['model_year', 'milage', 'Vehicle_Age', 'Is_Luxury_Brand']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 9 | ['brand', 'model', 'fuel_type', 'engine', 'transmission', ...]\n",
      "\t\t('float', [])     : 5 | ['Mileage_per_Year', 'milage_with_age', 'Mileage_per_Year_with_age', 'LGBM_MAE', 'LGBM_MSE_diff']\n",
      "\t\t('int', [])       : 3 | ['model_year', 'milage', 'Vehicle_Age']\n",
      "\t\t('int', ['bool']) : 2 | ['clean_title', 'Is_Luxury_Brand']\n",
      "\t0.9s = Fit runtime\n",
      "\t19 features in original data used to generate 19 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 14.14 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.96s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Included models: ['GBM', 'CAT'] (Specified by `included_model_types`, all other model types will be skipped)\n",
      "Fitting 36 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1771.65s of the 2658.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.35%)\n",
      "\t-72610.3089\t = Validation score   (-root_mean_squared_error)\n",
      "\t87.57s\t = Training   runtime\n",
      "\t6.48s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1661.58s of the 2548.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.35%)\n",
      "\t-72850.1875\t = Validation score   (-root_mean_squared_error)\n",
      "\t79.67s\t = Training   runtime\n",
      "\t3.74s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1563.28s of the 2449.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.36%)\n",
      "\t-72560.3041\t = Validation score   (-root_mean_squared_error)\n",
      "\t1267.03s\t = Training   runtime\n",
      "\t2.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 278.02s of the 1164.5s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.39%)\n",
      "\t-73327.4672\t = Validation score   (-root_mean_squared_error)\n",
      "\t102.0s\t = Training   runtime\n",
      "\t7.83s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 156.53s of the 1043.0s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.36%)\n",
      "\t-73134.5327\t = Validation score   (-root_mean_squared_error)\n",
      "\t140.25s\t = Training   runtime\n",
      "\t3.76s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 882.5s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.591, 'LightGBMXT_BAG_L1': 0.409}\n",
      "\t-72514.1573\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Included models: ['GBM', 'CAT'] (Specified by `included_model_types`, all other model types will be skipped)\n",
      "Fitting 36 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 881.86s of the 881.8s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.45%)\n",
      "\t-72568.9738\t = Validation score   (-root_mean_squared_error)\n",
      "\t111.06s\t = Training   runtime\n",
      "\t7.37s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 750.38s of the 750.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.43%)\n",
      "\t-72827.9033\t = Validation score   (-root_mean_squared_error)\n",
      "\t91.03s\t = Training   runtime\n",
      "\t4.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 642.45s of the 642.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.44%)\n",
      "\t-72555.5682\t = Validation score   (-root_mean_squared_error)\n",
      "\t528.17s\t = Training   runtime\n",
      "\t2.26s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 96.18s of the 96.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.50%)\n",
      "\t-73250.6176\t = Validation score   (-root_mean_squared_error)\n",
      "\t110.88s\t = Training   runtime\n",
      "\t8.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -37.25s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.417, 'LightGBMXT_BAG_L2': 0.333, 'LightGBMXT_BAG_L1': 0.125, 'LightGBMLarge_BAG_L2': 0.083, 'CatBoost_BAG_L2': 0.042}\n",
      "\t-72476.1059\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2696.92s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 577.4 rows/s (24065 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240929_214209\")\n"
     ]
    }
   ],
   "source": [
    "X['price'] = y\n",
    "\n",
    "predictor = TabularPredictor(label='price',\n",
    "                            eval_metric='rmse',\n",
    "                            problem_type='regression').fit(X,\n",
    "                                                       presets='best_quality',\n",
    "                                                       time_limit=3600*1,\n",
    "                                                       verbosity=2,\n",
    "                                                       num_gpus=0,\n",
    "                                                       included_model_types=['GBM', 'CAT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9408896d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T22:42:48.424934Z",
     "iopub.status.busy": "2024-09-29T22:42:48.420078Z",
     "iopub.status.idle": "2024-09-29T22:43:07.953725Z",
     "shell.execute_reply": "2024-09-29T22:43:07.952146Z"
    },
    "papermill": {
     "duration": 19.751157,
     "end_time": "2024-09-29T22:43:07.956454",
     "exception": false,
     "start_time": "2024-09-29T22:42:48.205297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188533</td>\n",
       "      <td>19142.844547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188534</td>\n",
       "      <td>77929.276288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>188535</td>\n",
       "      <td>57310.454533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>188536</td>\n",
       "      <td>30538.442072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188537</td>\n",
       "      <td>30902.855387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id         price\n",
       "0  188533  19142.844547\n",
       "1  188534  77929.276288\n",
       "2  188535  57310.454533\n",
       "3  188536  30538.442072\n",
       "4  188537  30902.855387"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predictor.predict(test)\n",
    "\n",
    "sub_blend = pd.read_csv('/kaggle/input/goodluck2/submission_9.csv')\n",
    "sample_sub = pd.read_csv('/kaggle/input/goodluck2/sample_submission.csv')\n",
    "sample_sub['price'] =  y_pred * 0.50 + sub_blend['price'] * 0.50 \n",
    "sample_sub.to_csv(\"submission.csv\", index=False)\n",
    "sample_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e87f06",
   "metadata": {
    "papermill": {
     "duration": 0.208593,
     "end_time": "2024-09-29T22:43:08.376051",
     "exception": false,
     "start_time": "2024-09-29T22:43:08.167458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba9f1a8",
   "metadata": {
    "papermill": {
     "duration": 0.216856,
     "end_time": "2024-09-29T22:43:08.805308",
     "exception": false,
     "start_time": "2024-09-29T22:43:08.588452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9057646,
     "sourceId": 76728,
     "sourceType": "competition"
    },
    {
     "datasetId": 2477667,
     "sourceId": 4202342,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3742543,
     "sourceId": 6478229,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5789463,
     "sourceId": 9511144,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 198790064,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 198804942,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4202.958193,
   "end_time": "2024-09-29T22:43:14.165475",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-29T21:33:11.207282",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
